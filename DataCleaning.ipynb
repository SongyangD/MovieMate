{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "684c20a9",
   "metadata": {},
   "source": [
    "• Multiple datasets contain information about movies, we will merge those data sets by some common\n",
    "columns(primary key, eg:imdb id), and remove duplicates.\n",
    "\n",
    "• Remove duplicates and redundancy in the Peoeple dataset.\n",
    "\n",
    "• No imdb id in the Oscar database:\n",
    "\n",
    "(a) Use year and movie name as the merging key to attach the Imdb id from the Movie table.\n",
    "\n",
    "(b) Remove any invalid data.\n",
    "\n",
    "(c) Create a boolean attribute in the Movie table to indicate whether the movie has any kind of\n",
    "Oscar nomination or not.\n",
    "\n",
    "• Using Python to scrape the movie descriptions from IMDb.\n",
    "\n",
    "• Using Python to scrape the URL of people’s profile photos from IMDb, and create an additional\n",
    "column Photo in the People table to store the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b24c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple datasets contain information about movies, \n",
    "#we will merge those data sets by some common columns(primary key, eg:imdb id), \n",
    "#and remove duplicates.\n",
    "imdb_movies = pd.read_csv('IMDB movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561dce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No longer use rating table\n",
    "# imdb_movie_rating = pd.read_csv('IMDB ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import movie_genre table\n",
    "movie_genre = pd.read_csv('MovieGenre.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_movies.columns)\n",
    "imdb_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e297b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_movies.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d290d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_genre.columns)\n",
    "movie_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a243ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_genre.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get length of each string in imdbId column\n",
    "imdbId_lengths = movie_genre['imdbId'].astype(str).str.len()\n",
    "# Print summary statistics of imdbId_lengths\n",
    "print(imdbId_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb40cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add leading zeros and convert to string\n",
    "movie_genre['imdbId'] = movie_genre['imdbId'].apply(lambda x: str(x).zfill(7))\n",
    "\n",
    "# Add 'tt' to beginning of string\n",
    "movie_genre['imdbId'] = 'tt' + movie_genre['imdbId']\n",
    "\n",
    "#print(movie_genre.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename imdbId column to Imdb_id\n",
    "movie_genre.rename(columns={'imdbId': 'imdb_title_id'}, inplace=True)\n",
    "\n",
    "duplicates = movie_genre.duplicated(subset='imdb_title_id', keep=False)\n",
    "if any(duplicates):\n",
    "    print(\"There are duplicated rows by imdb_name_id in movie_genre.\")\n",
    "else:\n",
    "    print(\"There are no duplicated rows by imdb_name_id in movie_genre.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a97874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_genre.drop_duplicates(subset=['imdb_title_id'], inplace=True)\n",
    "print(movie_genre.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad65c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = imdb_movies.duplicated(subset='imdb_title_id', keep=False)\n",
    "if any(duplicates):\n",
    "    print(\"There are duplicated rows by imdb_name_id in imdb_movies.\")\n",
    "else:\n",
    "    print(\"There are no duplicated rows by imdb_name_id in imdb_movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = imdb_movies.duplicated(subset=['year','title'], keep=False)\n",
    "print(\"Number of duplicates:\", duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an inner join on movie_id to combine the tables\n",
    "movie_data = pd.merge(imdb_movies, movie_genre[['imdb_title_id', 'Imdb Link', 'IMDB Score', 'Poster']], \n",
    "                                               on='imdb_title_id')\n",
    "\n",
    "print(movie_data.shape)\n",
    "\n",
    "# Filter out tuples with missing or invalid poster URLs\n",
    "movie_data = movie_data[movie_data['Poster'].notna() & (movie_data['Poster'] != '')]\n",
    "\n",
    "# Print the resulting dataframe\n",
    "# movie_data.head()\n",
    "\n",
    "print(movie_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out tuples with an IMDb score less than 6.5\n",
    "movie_data = movie_data.drop(movie_data[movie_data['IMDB Score'] < 6.5].index)\n",
    "\n",
    "movie_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0bd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('imdb_movies_new shape:', imdb_movies_new.shape)\n",
    "# print('imdb_movie_rating shape:', imdb_movie_rating.shape)\n",
    "# print('imdb_movies_new columns:', imdb_movies_new.columns)\n",
    "# print('imdb_movie_rating columns:', imdb_movie_rating.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_movies_new = imdb_movies_new.merge(imdb_movie_rating, \n",
    "#                      left_on='imdb_title_id', right_on='imdb_title_id', how='left')\n",
    "# imdb_movies_new.head()\n",
    "# Print the shape and column names of the merged dataframe\n",
    "# print('imdb_movies_new after merge:', imdb_movies_new.shape)\n",
    "# print('imdb_movies_new columns after merge:', imdb_movies_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9da546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "print('movie_data columns:', movie_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522abba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to keep and rename 'Poster' to 'poster_url'\n",
    "movie_data_final = movie_data.loc[:, ['imdb_title_id', 'title', 'original_title', 'year', 'genre', 'duration',\n",
    "                                'country', 'language', 'director', 'description', 'avg_vote', 'votes', 'Poster']]\n",
    "movie_data_final = movie_data_final.rename(columns={'Poster': 'poster_url'})\n",
    "print('movie_data_final columns:', movie_data_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e258cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_data['title'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No imdb id in the Oscar database:\n",
    "#(a) Use year and movie name as the merging key to attach the Imdb id from the Movie table.\n",
    "#(b) Remove any invalid data.\n",
    "#(c) Create a boolean attribute in the Movie table to indicate whether the movie has any kind of Oscar nomination or not.\n",
    "oscar = pd.read_csv('the_oscar_award.csv')\n",
    "oscar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ad718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oscar.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b026c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar.dropna(subset=['film'], how='any', inplace=True)\n",
    "oscar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = imdb_movies.duplicated(subset='imdb_title_id', keep=False)\n",
    "if any(duplicates):\n",
    "    print(\"There are duplicated rows by imdb_name_id in imdb_movies.\")\n",
    "else:\n",
    "    print(\"There are no duplicated rows by imdb_name_id in imdb_movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d32c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar['film'] = oscar['film'].str.lower().str.strip()\n",
    "imdb_movies_title = movie_data.loc[:, ['year','original_title','imdb_title_id','title']]\n",
    "imdb_movies_title['original_title'] = imdb_movies_title['original_title'].str.lower().str.strip()\n",
    "imdb_movies_title['title'] = imdb_movies_title['title'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ced0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on our test, the film in Oscar data could be matched to either title or original_title in imdb_movies data\n",
    "# So we created a dictionary to merge the imdb_title_id to oscar data\n",
    "# create a dictionary mapping (year, film) pairs to imdb_title_ids\n",
    "film_to_title_id = {}\n",
    "\n",
    "# match 'film' in Oscar dataset to 'title' in IMDB dataset\n",
    "title_to_id = dict(zip(zip(imdb_movies_title['year'], imdb_movies_title['title']), imdb_movies_title['imdb_title_id']))\n",
    "film_to_title_id.update(title_to_id)\n",
    "\n",
    "# match 'film' in Oscar dataset to 'original_title' in IMDB dataset\n",
    "orig_title_to_id = dict(zip(zip(imdb_movies_title['year'], imdb_movies_title['original_title']), imdb_movies_title['imdb_title_id']))\n",
    "film_to_title_id.update(orig_title_to_id)\n",
    "\n",
    "# create a new column in Oscar dataset with imdb_title_id values\n",
    "oscar['imdb_title_id'] = oscar[['year_film', 'film']].apply(lambda x: film_to_title_id.get(tuple(x)), axis=1)\n",
    "\n",
    "# delete oscar movies where imdb_title_id is missing\n",
    "oscar.dropna(subset=['imdb_title_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba306781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oscar.shape)\n",
    "print(oscar.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df346aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_data = oscar.merge(movie_data[['imdb_title_id', 'original_title']], on='imdb_title_id', how='left')\n",
    "\n",
    "# Rename 'title' column to 'movie_title'\n",
    "oscar_data = oscar_data.rename(columns={'original_title': 'movie_title'})\n",
    "\n",
    "# Drop 'film' column\n",
    "oscar_data = oscar_data.drop(columns=['film'])\n",
    "\n",
    "oscar_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = oscar_data.duplicated(subset=['ceremony','category','name','movie_title'], keep=False)\n",
    "print(\"Number of duplicates:\", duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e152177",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = oscar_data.duplicated(subset=['ceremony', 'category', 'name', 'movie_title'], keep=False)\n",
    "oscar_data.drop(oscar_data.loc[duplicates & ~oscar_data['winner']].index, inplace=True)\n",
    "duplicates = oscar_data.duplicated(subset=['ceremony', 'category', 'name', 'movie_title'], keep=False)\n",
    "print(oscar_data[duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data\n",
    "oscar_data.to_csv('oscar_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean column indicating if the imdb_title_id is in oscar_data\n",
    "movie_data_final['Oscar_nominated'] = movie_data_final['imdb_title_id'].isin(oscar_data['imdb_title_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75156aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ca68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data\n",
    "# movie_data_final.to_csv('movie_data_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates and redundancy in the Peoeple dataset.\n",
    "imdb_names = pd.read_csv('IMDB names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_names.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4441688",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = imdb_names.duplicated(subset='imdb_name_id', keep=False)\n",
    "\n",
    "if any(duplicates):\n",
    "    print(\"There are duplicated rows by imdb_name_id.\")\n",
    "else:\n",
    "    print(\"There are no duplicated rows by imdb_name_id.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7991d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columncs\n",
    "imdb_names = imdb_names.loc[:, ['imdb_name_id', 'name', 'birth_name', \n",
    "                                       'date_of_birth', 'place_of_birth', \n",
    "                                       'date_of_death', 'height', 'bio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e47b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_people = pd.read_csv('IMDb title_principals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_people.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ab13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an inner join on movie_id to combine the tables\n",
    "staff_data = pd.merge(movie_data['imdb_title_id'], movie_people, on='imdb_title_id')\n",
    "\n",
    "# Filter the resulting dataframe to include only the rows where the category is \"actor\"\n",
    "#actors = merged_data[merged_data['category'] == 'actor']\n",
    "staff_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = staff_data.duplicated(subset=['imdb_title_id', 'ordering'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff_data = staff_data.loc[:, ['imdb_title_id', 'ordering', 'imdb_name_id', \n",
    "                                       'category']]\n",
    "\n",
    "staff_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data\n",
    "# staff_data.to_csv('movie_people.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_people_df = pd.read_csv('movie_people.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4566e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts_df = movie_people_df.groupby(\"imdb_name_id\")[\"category\"].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Compute the total number of rows for each person\n",
    "total_counts_df = movie_people_df.groupby(\"imdb_name_id\").size().to_frame(name=\"num_all\")\n",
    "\n",
    "# Combine the category counts and total counts into a single DataFrame\n",
    "counts_df = pd.concat([category_counts_df, total_counts_df], axis=1)\n",
    "\n",
    "# Compute the sum of the num_actor, num_actress, and num_director columns\n",
    "if \"num_actor\" in counts_df.columns and \"num_actress\" in counts_df.columns and \"num_director\" in counts_df.columns:\n",
    "    counts_df[\"num_aad\"] = counts_df[\"num_actor\"] + counts_df[\"num_actress\"] + counts_df[\"num_director\"]\n",
    "else:\n",
    "    counts_df[\"num_aad\"] = 0\n",
    "\n",
    "# Sort the DataFrame by the num_aad column in descending order\n",
    "counts_df = counts_df.sort_values(\"num_aad\", ascending=False)\n",
    "\n",
    "# Rename the columns to include the \"num_\" prefix\n",
    "counts_df = counts_df.add_prefix(\"num_\")\n",
    "\n",
    "# Reset the index to include the \"imdb_name_id\" column\n",
    "counts_df = counts_df.reset_index()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique people in the merged dataframe\n",
    "unique_people = staff_data['imdb_name_id'].nunique()\n",
    "\n",
    "# Print the number of unique people\n",
    "print(\"Number of unique people after merge:\", unique_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the imdb_name_ids that exist in the staff_data DataFrame\n",
    "valid_ids = staff_data['imdb_name_id'].unique()\n",
    "\n",
    "# Filter the imdb_names DataFrame by checking if the imdb_name_id column is in valid_ids\n",
    "imdb_names_new = imdb_names[imdb_names['imdb_name_id'].isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_names_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d93d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_names_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_names_new.to_csv('people.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e752121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Python to scrape the URL of people’s profile photos from IMDb, and create an additional column Photo in the People table to store the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install IMDbPY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import IMDb\n",
    "import concurrent.futures\n",
    "import csv\n",
    "import socket\n",
    "import pandas as pd\n",
    "import requests\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_names_new = pd.read_csv('people.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imdb_names_new = pd.read_csv('people.csv')\n",
    "\n",
    "#imdb_names_new = imdb_names_new.iloc[:1000]\n",
    "\n",
    "# Divide the DataFrame into 10 equal parts\n",
    "parts = np.array_split(imdb_names_new, 100)\n",
    "\n",
    "# Define a function to fetch the headshot for a single IMDb id and write the photo URL to a CSV file\n",
    "def get_headshot(imdb_id):\n",
    "    try:\n",
    "        person = imdb.get_person(imdb_id)\n",
    "        photo_url = person.get(\"headshot\", None)\n",
    "        return photo_url\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching headshot for IMDb id {imdb_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch the headshots for all IMDb ids in each part using parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i, part in enumerate(parts):\n",
    "        imdb_ids = [int(imdb_name_id[2:]) for imdb_name_id in part[\"imdb_name_id\"]]\n",
    "        futures = [executor.submit(get_headshot, imdb_id) for imdb_id in imdb_ids]\n",
    "        photo_urls = [future.result() for future in futures]\n",
    "        with open(f\"photo_urls_{i}.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            try:\n",
    "                for imdb_id, photo_url in zip(imdb_ids, photo_urls):\n",
    "                    writer.writerow([imdb_id, photo_url])\n",
    "            finally:\n",
    "                f.close()\n",
    "        # Print the time finished for the part\n",
    "        print(f\"Part {i} finished at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        # Clear the memory\n",
    "        del imdb_ids, futures, photo_urls\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all CSV files and stack them together\n",
    "df_list = []\n",
    "for i in range(100):\n",
    "    file_name = f\"photo_urls_{i}.csv\"\n",
    "    df = pd.read_csv(file_name, header=None, names=[\"imdb_name_id_int\", \"photo_url\"])\n",
    "    df_list.append(df)\n",
    "\n",
    "people_urls = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Add leading zeros to imdb_name_id_int and prefix with \"nm\"\n",
    "people_urls[\"imdb_name_id\"] = \"nm\" + people_urls[\"imdb_name_id_int\"].apply(lambda x: str(x).zfill(7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the format and size suffix of urls \n",
    "\n",
    "import re\n",
    "\n",
    "people_urls['photo_url'] = people_urls['photo_url'].str.replace('\\._V1_.+', '', regex=True).str.replace('\\._V1_', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270313d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_names_final = imdb_names_new.merge(people_urls[['imdb_name_id','photo_url']], \n",
    "                     left_on='imdb_name_id', right_on='imdb_name_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_names_final = pd.read_csv('people_test.csv')\n",
    "max_len = imdb_names_final[\"bio\"].str.len().max()\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_names_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_counts = imdb_names_final[\"bio\"].str.len().value_counts()\n",
    "\n",
    "# Print the resulting distribution\n",
    "print(length_counts.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52210608",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_names_final.to_csv('people_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get length of each string in imdbId column\n",
    "lengths = people_urls['photo_url'].astype(str).str.len()\n",
    "# Print summary statistics of imdbId_lengths\n",
    "print(lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_movie_forposter = pd.read_csv('movie_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6656fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(imdb_movie_forposter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa04ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import IMDb\n",
    "\n",
    "parts = np.array_split(imdb_movie_forposter,100)\n",
    "\n",
    "# Define a function to fetch the poster for a single IMDb id and write the photo URL to a CSV file\n",
    "def get_poster(imdb_id):\n",
    "    try:\n",
    "        imdb = IMDb()\n",
    "        movie = imdb.get_movie(imdb_id)\n",
    "        poster_url = movie.get('full-size cover url')\n",
    "        return poster_url\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching poster for IMDb id {imdb_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch the poster for all IMDb ids in each part using parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i, part in enumerate(parts):\n",
    "        if i < 83:\n",
    "            continue\n",
    "        imdb_ids = [int(imdb_title_id[2:]) for imdb_title_id in part[\"imdb_title_id\"]]\n",
    "        futures = [executor.submit(get_poster, imdb_id) for imdb_id in imdb_ids]\n",
    "        poster_urls = [future.result() for future in futures]\n",
    "        with open(f\"movie_poster_urls_{i}.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            try:\n",
    "                for imdb_id, poster_url in zip(imdb_ids, poster_urls):\n",
    "                    writer.writerow([imdb_id, poster_url])\n",
    "            finally:\n",
    "                f.close()\n",
    "        # Print the time finished for the part\n",
    "        print(f\"Part {i} finished at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        # Clear the memory\n",
    "        del imdb_ids, futures, poster_urls\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all CSV files and stack them together\n",
    "df_list = []\n",
    "for i in range(100):\n",
    "    file_name = f\"movie_poster_urls_{i}.csv\"\n",
    "    df = pd.read_csv(file_name, header=None, names=[\"imdb_title_id_int\", \"poster_url\"])\n",
    "    df_list.append(df)\n",
    "\n",
    "movie_poster_urls = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Add leading zeros to imdb_name_id_int and prefix with \"nm\"\n",
    "movie_poster_urls[\"imdb_title_id\"] = \"tt\" + movie_poster_urls[\"imdb_title_id_int\"].apply(lambda x: str(x).zfill(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195dbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_movie_forposter = imdb_movie_forposter.drop('poster_url', axis=1)\n",
    "movie_poster_final = imdb_movie_forposter.merge(movie_poster_urls[['imdb_title_id','poster_url']], \n",
    "                                                 left_on='imdb_title_id', right_on='imdb_title_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc002ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_poster_final = movie_poster_final.rename(columns={\"title\": \"original_title\", \"original_title\": \"title\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6543f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", movie_poster_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01049a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = movie_poster_final[\"description\"].str.len().max()\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_poster_final2 = movie_poster_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a635e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", movie_poster_final2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e072298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_poster_final.to_csv('movie_test.csv', index=False)\n",
    "movie_poster_final2.to_csv('movie_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all genres with frequencies sorted by frequency\n",
    "genres = {}\n",
    "for genre_list in movie_poster_final[\"genre\"].str.split(\", \"):\n",
    "    for genre in genre_list:\n",
    "        if genre in genres:\n",
    "            genres[genre] += 1\n",
    "        else:\n",
    "            genres[genre] = 1\n",
    "genres_sorted = sorted(genres.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Genres: \", genres_sorted)\n",
    "\n",
    "# list all languages with frequencies sorted by frequency\n",
    "languages = {}\n",
    "for language_list in movie_poster_final[\"language\"]:\n",
    "    if isinstance(language_list, str):\n",
    "        for language in language_list.split(\", \"):\n",
    "            if language in languages:\n",
    "                languages[language] += 1\n",
    "            else:\n",
    "                languages[language] = 1\n",
    "languages_sorted = sorted(languages.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Languages: \", languages_sorted)\n",
    "\n",
    "# list all countries with frequencies sorted by frequency\n",
    "countries = {}\n",
    "for country_list in movie_poster_final[\"country\"].str.split(\", \"):\n",
    "    for country in country_list:\n",
    "        if country in countries:\n",
    "            countries[country] += 1\n",
    "        else:\n",
    "            countries[country] = 1\n",
    "countries_sorted = sorted(countries.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Countries: \", countries_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e29397",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_poster_final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv('movie_test2.csv')\n",
    "print(movie_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in movie_data.columns:\n",
    "    if movie_data[column].dtype == 'object':\n",
    "        max_len = movie_data[column].str.len().max()\n",
    "        print(f\"The maximum length of '{column}' is {max_len}\")\n",
    "    else:\n",
    "        print(f\"'{column}' is not a string column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_data = pd.read_csv('oscar_data_test.csv')\n",
    "print(oscar_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_data = pd.read_csv('people_test.csv')\n",
    "print(people_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a765ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_data = people_data[people_data['name'].notnull() & (people_data['name'] != '')]\n",
    "print(people_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_people = pd.read_csv('movie_people.csv')\n",
    "print(movie_people.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ed7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_people_new = movie_people[movie_people['imdb_title_id'].isin(movie_data['imdb_title_id']) &\n",
    "                                movie_people['imdb_name_id'].isin(people_data['imdb_name_id'])]\n",
    "print(movie_people_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbaa3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_data_new = people_data[people_data['imdb_name_id'].isin(movie_people_new['imdb_name_id'])]\n",
    "print(people_data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_data_new = oscar_data[oscar_data['imdb_title_id'].isin(movie_data['imdb_title_id'])]\n",
    "print(oscar_data_new.shape)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa515c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data['Oscar_nominated'] = movie_data['imdb_title_id'].isin(oscar_data_new['imdb_title_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_str):\n",
    "    try:\n",
    "        # try parsing the date as mm/dd/yy format\n",
    "        return pd.to_datetime(date_str, format='%m/%d/%y').strftime('%m/%d/%Y')\n",
    "    except:\n",
    "        try:\n",
    "            # try parsing the date as mm/dd/yyyy format\n",
    "            return pd.to_datetime(date_str, format='%m/%d/%Y').strftime('%m/%d/%Y')\n",
    "        except:\n",
    "            try:\n",
    "                # try parsing the date as yyyy-mm-dd format\n",
    "                return pd.to_datetime(date_str, format='%Y-%m-%d').strftime('%m/%d/%Y')\n",
    "            except:\n",
    "                try:\n",
    "                    # try extracting the year from the date string\n",
    "                    year = re.search('\\d{4}', date_str).group(0)\n",
    "                    return f'01/01/{year}'\n",
    "                except:\n",
    "                    # for all other cases, return None\n",
    "                    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715945bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_data_new['date_of_birth'] = people_data_new['date_of_birth'].apply(convert_date)\n",
    "people_data_new['date_of_death'] = people_data_new['date_of_death'].apply(convert_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ece769",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = people_data_new['date_of_birth'].str.len().max()\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ed3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.to_csv('final/movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92232685",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_people_new.to_csv('final/movie_people.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_data_new.to_csv('final/people_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_data_new.to_csv('final/oscar_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d7e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9119b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
